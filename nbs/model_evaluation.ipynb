{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.019330049813105\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "from robot_animation.data_processing import process_raw_robot_data, robot_data_to_qpos_qvel\n",
    "\n",
    "import numpy as np\n",
    "# Load the trained model from the zip file\n",
    "model = PPO.load(\"../models/ppo_robot_animation_qkqryqza/model.zip\")\n",
    "csv_path = \"../data/kuka_2.csv\"\n",
    "\n",
    "frame_rate = 153\n",
    "\n",
    "animation_df = process_raw_robot_data(csv_path)\n",
    "target_qpos, _ = robot_data_to_qpos_qvel(animation_df, num_q=7)\n",
    "\n",
    "target_qvel = np.zeros_like(target_qpos)\n",
    "target_qvel[1:] = (target_qpos[1:] - target_qpos[:-1]) * frame_rate # TODO: shift this upstream\n",
    "target_qvel[0] = np.zeros(target_qpos.shape[1])  \n",
    "\n",
    "\n",
    "eval_env = gym.make(\n",
    "    \"RobotAnimationEnv-kuka\",\n",
    "    animation_frame_rate=frame_rate,\n",
    "    target_qpos=target_qpos,\n",
    "    target_qvel=target_qvel,\n",
    "    num_q=7,\n",
    "    reset_noise_scale=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "eval_env.reset()\n",
    "\n",
    "def evaluate_policy(model: PPO, env: gym.Env, num_episodes: int = 1) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Evaluate the trained policy and return frames for visualization.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PPO model\n",
    "        env: Environment to evaluate in\n",
    "        num_episodes: Number of episodes to run\n",
    "        \n",
    "    Returns:\n",
    "        List of frames from all episodes\n",
    "    \"\"\"\n",
    "    all_frames = []\n",
    "    \n",
    "    for _ in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        print(env.unwrapped.target_base_rotation)\n",
    "        target_joint_0 = np.array([2.9])\n",
    "        done = False\n",
    "        episode_frames = []\n",
    "        \n",
    "        while not done:\n",
    "            # obs = np.concatenate([obs, target_joint_0])\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            frame = env.render()\n",
    "            \n",
    "            if frame is not None:\n",
    "                episode_frames.append(frame)\n",
    "        \n",
    "        all_frames.extend(episode_frames)\n",
    "    \n",
    "    return all_frames\n",
    "\n",
    "\n",
    "frames = evaluate_policy(model, eval_env, num_episodes=1)\n",
    "\n",
    "eval_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
