{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinygrad.nn\n",
    "import numpy as np\n",
    "from tinygrad import nn , Tensor\n",
    "\n",
    "\n",
    "\n",
    "def layer_init(layer: nn.Linear, std=np.sqrt(2), bias_const=0.0):\n",
    "    \"\"\"CleanRL's default layer initialization\"\"\"\n",
    "    layer.weight = tiny_orthogonal_(layer.weight, std)\n",
    "    layer.bias = tiny_constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "from tinygrad import nn \n",
    "def tiny_orthogonal_(tensor: Tensor, gain=1, generator=None):\n",
    "    \"\"\"\n",
    "    NOTE: Since initialization occurs only once, we are being lazy and using numpy linear algebra to perform certain operations.\n",
    "    \"\"\"\n",
    "    if tensor.ndim < 2:\n",
    "        raise ValueError(\"Only tensors with 2 or more dimensions are supported\")\n",
    "\n",
    "    if tensor.numel() == 0:\n",
    "        return tensor # no-op for empty tensors\n",
    "\n",
    "    rows, cols = tensor.shape[0], tensor.numel() // tensor.shape[0]\n",
    "    flattened = Tensor.randn(rows, cols) # figure out if it has the same device configs as the input tensor\n",
    "\n",
    "    if rows < cols:\n",
    "        flattened = flattened.transpose()\n",
    "\n",
    "    # for now, we use numpy to compute the qr factorization\n",
    "    q, r = np.linalg.qr(flattened.numpy())\n",
    "\n",
    "    d = np.diag(r, 0)\n",
    "    ph = np.sign(d)\n",
    "    q *= ph\n",
    "\n",
    "    if rows < cols:\n",
    "        q.transpose()\n",
    "\n",
    "    return Tensor(q).mul(gain)\n",
    "\n",
    "def tiny_constant_(tensor: Tensor, val: float):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return Tensor.ones(tensor.shape) * val\n",
    "    \n",
    "\n",
    "from tinygrad import nn \n",
    "\n",
    "\n",
    "class TinyPolicy:\n",
    "    def __init__(self, policy):\n",
    "        self.policy = policy\n",
    "        self.is_continuous = hasattr(policy, 'is_continuous') and policy.is_continuous\n",
    "    \n",
    "    def __call__(self, x, action=None):\n",
    "        return self.get_action_and_value(x, action)\n",
    "\n",
    "    def get_value(self, x, state=None):\n",
    "        _, value = self.policy(x)\n",
    "        return value\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits, value = self.policy(x)\n",
    "        action, logprob, entropy = sample_logits(logits, action, self.is_continuous)\n",
    "        return action, logprob, entropy, value\n",
    "    \n",
    "class Critic:\n",
    "    def __init__(self, obs_size, hidden_size):\n",
    "        self.l1 = layer_init(tinygrad.nn.Linear(obs_size, hidden_size))\n",
    "        self.l2 = layer_init(tinygrad.nn.Linear(hidden_size, hidden_size))\n",
    "        self.l3 = layer_init(tinygrad.nn.Linear(hidden_size, 1))\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        x = self.l1(x).tanh()\n",
    "        x = self.l2(x).tanh()\n",
    "        return self.l3(x)\n",
    "\n",
    "class ActorEncoder:\n",
    "    def __init__(self, obs_size, hidden_size):\n",
    "        self.l1 = layer_init(tinygrad.nn.Linear(obs_size, hidden_size))\n",
    "        self.l2 = layer_init(tinygrad.nn.Linear(hidden_size, hidden_size))\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        x = self.l1(x).tanh()\n",
    "        return self.l2(x).tanh()\n",
    "\n",
    "class TinyCleanRLPolicy(TinyPolicy):\n",
    "    def __init__(self, envs, hidden_size=64):\n",
    "        super().__init__(policy=None)  # Just to get the right init\n",
    "        self.is_continuous = True\n",
    "\n",
    "        # self.obs_size = np.array(envs.single_observation_space.shape).prod()\n",
    "        # action_size = np.prod(envs.single_action_space.shape)\n",
    "\n",
    "        ## figuring out how to normalize observations will be an important step, but leaving it out for now\n",
    "        action_size = 1\n",
    "        self.obs_size = 1\n",
    "        self.critic = Critic(self.obs_size, hidden_size)\n",
    "        self.actor_encoder = ActorEncoder(self.obs_size, hidden_size)\n",
    "        self.actor_decoder_mean = layer_init(tinygrad.nn.Linear(hidden_size, action_size), std=0.01)\n",
    "        self.actor_decoder_logstd = Tensor.zeros(1, action_size)\n",
    "\n",
    "\n",
    "\n",
    "policy = TinyCleanRLPolicy(\"hypothetical env\", hidden_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "import torch\n",
    "a = Normal(torch.tensor([1.0, 2.0]), torch.tensor([1.0, 1.0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "a.log_prob(torch.tensor([1.0, 2.0])).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of c (10, 3)\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import TinyJit, Tensor\n",
    "weight = Tensor.randn(10, 3)\n",
    "@TinyJit\n",
    "def forward(x: Tensor, indices: list[int]):\n",
    "  c = (x[indices] * weight).contiguous()\n",
    "  print(f\"shape of c {c.shape}\")\n",
    "  c.sum(0).realize()\n",
    "\n",
    "x = Tensor.randn(10)\n",
    "forward(x, [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad impor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "step    0, loss 2.31, acc 21.34%\n",
      "step  100, loss 0.26, acc 93.31%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m7000\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     loss = \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_num%\u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     51\u001b[39m         model.eval()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mstep\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     41\u001b[39m optim.zero_grad()\n\u001b[32m     42\u001b[39m loss = nn.functional.cross_entropy(model(X), Y)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m optim.step()\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(\"Using device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get MNIST data \n",
    "transform = transforms.ToTensor()\n",
    "mnist_train = datasets.MNIST('./', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST('./', train=False, transform=transform)\n",
    "\n",
    "X_train, Y_train = mnist_train.data.float()/255, mnist_train.targets\n",
    "X_test, Y_test = mnist_test.data.float()/255, mnist_test.targets\n",
    "X_train = X_train.unsqueeze(1) # Add channel dimension\n",
    "X_test = X_test.unsqueeze(1)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.l2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.l3 = nn.Linear(1600, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.max_pool2d(torch.relu(self.l1(x)), 2)\n",
    "        x = torch.max_pool2d(torch.relu(self.l2(x)), 2)\n",
    "        x = self.dropout(x.flatten(1))\n",
    "        return self.l3(x)\n",
    "\n",
    "model = Model()\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "batch_size = 128\n",
    "def step():\n",
    "    model.train()\n",
    "    indices = torch.randint(len(X_train), (batch_size,))\n",
    "    X, Y = X_train[indices], Y_train[indices]\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss = nn.functional.cross_entropy(model(X), Y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "# Train model\n",
    "for step_num in range(7000):\n",
    "    loss = step()\n",
    "    if step_num%100 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            acc = (model(X_test).argmax(dim=1) == Y_test).float().mean().item()\n",
    "        print(f\"step {step_num:4d}, loss {loss.item():.2f}, acc {acc*100.:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: METAL\n",
      "step    0, loss 43.87, acc 15.73%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_num%\u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     41\u001b[39m         Tensor.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         acc = \u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_num\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc*\u001b[32m100.\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtimeit\u001b[39;00m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:330\u001b[39m, in \u001b[36mTensor.item\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[33;03mReturns the value of this tensor as a standard Python number.\u001b[39;00m\n\u001b[32m    323\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    327\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numel() == \u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmust have one element for item\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[(\u001b[32m0\u001b[39m,) * \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.shape)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:318\u001b[39m, in \u001b[36mTensor.data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m all_int(\u001b[38;5;28mself\u001b[39m.shape), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mno data if shape is symbolic, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.shape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING \u001b[38;5;129;01mor\u001b[39;00m sys.version_info < (\u001b[32m3\u001b[39m, \u001b[32m12\u001b[39m): \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtype.base.fmt != \u001b[33m\"\u001b[39m\u001b[33me\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mmemoryview\u001b[39m, \u001b[38;5;28mself\u001b[39m._data().cast(\u001b[38;5;28mself\u001b[39m.dtype.base.fmt) \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.shape \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.cast(\u001b[38;5;28mself\u001b[39m.dtype.base.fmt, \u001b[38;5;28mself\u001b[39m.shape))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:300\u001b[39m, in \u001b[36mTensor._data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.shape: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(\u001b[38;5;28mbytearray\u001b[39m(\u001b[32m0\u001b[39m))\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# NOTE: this realizes on the object from as_buffer being a Python object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m cpu = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCPU\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m buf = cast(UOp, cpu.lazydata).base.realized\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcast(UOp,\u001b[38;5;250m \u001b[39mcpu.lazydata).base\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m was not realized\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:262\u001b[39m, in \u001b[36mTensor.realize\u001b[39m\u001b[34m(self, do_update_stats, *lst)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrealize\u001b[39m(\u001b[38;5;28mself\u001b[39m, *lst:Tensor, do_update_stats=\u001b[38;5;28;01mTrue\u001b[39;00m) -> Tensor:\n\u001b[32m    261\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Triggers the computation needed to create these Tensor(s).\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m   \u001b[43mrun_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_with_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlst\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_update_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_update_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/engine/realize.py:171\u001b[39m, in \u001b[36mrun_schedule\u001b[39m\u001b[34m(schedule, var_vals, do_update_stats)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ei \u001b[38;5;129;01min\u001b[39;00m lower_schedule(schedule):\n\u001b[32m    170\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(capturing) \u001b[38;5;129;01mand\u001b[39;00m CAPTURING: capturing[\u001b[32m0\u001b[39m].add(ei)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m   \u001b[43mei\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_update_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_update_stats\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/engine/realize.py:127\u001b[39m, in \u001b[36mExecItem.run\u001b[39m\u001b[34m(self, _var_vals, wait, jit, do_update_stats)\u001b[39m\n\u001b[32m    125\u001b[39m var_vals = {} \u001b[38;5;28;01mif\u001b[39;00m _var_vals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _var_vals\n\u001b[32m    126\u001b[39m bufs = [cast(Buffer, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bufs] \u001b[38;5;28;01mif\u001b[39;00m jit \u001b[38;5;28;01melse\u001b[39;00m [cast(Buffer, x).ensure_allocated() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bufs]\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m et = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_update_stats:\n\u001b[32m    129\u001b[39m   GlobalCounters.kernel_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/engine/realize.py:93\u001b[39m, in \u001b[36mBufferCopy.__call__\u001b[39m\u001b[34m(self, rawbufs, var_vals, wait)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dest.size == src.size \u001b[38;5;129;01mand\u001b[39;00m dest.dtype == src.dtype, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbuffer copy mismatch, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest.size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m st = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m     95\u001b[39m   Device[dest.device].synchronize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/engine/realize.py:88\u001b[39m, in \u001b[36mBufferCopy.copy\u001b[39m\u001b[34m(self, dest, src)\u001b[39m\n\u001b[32m     86\u001b[39m   src.allocator._copyout(dest.allocator._as_buffer(dest._buf), src._buf)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   dest.copyin(\u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallow_zero_copy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/device.py:152\u001b[39m, in \u001b[36mBuffer.as_buffer\u001b[39m\u001b[34m(self, allow_zero_copy, force_zero_copy)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mas_buffer\u001b[39m(\u001b[38;5;28mself\u001b[39m, allow_zero_copy=\u001b[38;5;28;01mFalse\u001b[39;00m, force_zero_copy=\u001b[38;5;28;01mFalse\u001b[39;00m) -> \u001b[38;5;28mmemoryview\u001b[39m:\n\u001b[32m    150\u001b[39m   \u001b[38;5;66;03m# zero copy with as_buffer (disabled by default due to use after free)\u001b[39;00m\n\u001b[32m    151\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (force_zero_copy \u001b[38;5;129;01mor\u001b[39;00m allow_zero_copy) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.allocator, \u001b[33m'\u001b[39m\u001b[33m_as_buffer\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.options.image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallocator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_as_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_zero_copy, \u001b[33m\"\u001b[39m\u001b[33mforce zero copy was passed, but copy is required\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copyout(\u001b[38;5;28mmemoryview\u001b[39m(\u001b[38;5;28mbytearray\u001b[39m(\u001b[38;5;28mself\u001b[39m.nbytes)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/runtime/ops_metal.py:220\u001b[39m, in \u001b[36mMetalAllocator._as_buffer\u001b[39m\u001b[34m(self, src)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_as_buffer\u001b[39m(\u001b[38;5;28mself\u001b[39m, src:MetalBuffer) -> \u001b[38;5;28mmemoryview\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdev\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m to_mv(cast(\u001b[38;5;28mint\u001b[39m, msg(\u001b[33m\"\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m\"\u001b[39m, objc_id)(src.buf).value), src.size + src.offset)[src.offset:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/runtime/ops_metal.py:81\u001b[39m, in \u001b[36mMetalDevice.synchronize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msynchronize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     80\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m cbuf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mtl_buffers_in_flight:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[43mwait_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     st, en = decimal.Decimal(cmdbuf_st_time(cbuf)) * \u001b[32m1000000\u001b[39m, decimal.Decimal(cmdbuf_en_time(cbuf)) * \u001b[32m1000000\u001b[39m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m PROFILE \u001b[38;5;129;01mand\u001b[39;00m (lb:=cmdbuf_label(cbuf)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/runtime/ops_metal.py:53\u001b[39m, in \u001b[36mwait_check\u001b[39m\u001b[34m(cbuf)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait_check\u001b[39m(cbuf: Any):\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   \u001b[43mmsg\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwaitUntilCompleted\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m   error_check(msg(\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m, objc_instance)(cbuf))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/runtime/ops_metal.py:43\u001b[39m, in \u001b[36mmsg.<locals>._msg\u001b[39m\u001b[34m(ptr, *args)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_msg\u001b[39m(ptr: objc_id, *args: Any) -> T: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Tinygrad MNIST implementation\n",
    "from tinygrad import Tensor, nn, TinyJit, Device\n",
    "from tinygrad.nn.datasets import mnist\n",
    "\n",
    "print(\"Using device:\", Device.DEFAULT)\n",
    "\n",
    "# Get MNIST data\n",
    "X_train, Y_train, X_test, Y_test = mnist()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.l1 = nn.Conv2d(1, 32, kernel_size=(3,3))\n",
    "        self.l2 = nn.Conv2d(32, 64, kernel_size=(3,3))\n",
    "        self.l3 = nn.Linear(1600, 10)\n",
    "\n",
    "    def __call__(self, x:Tensor) -> Tensor:\n",
    "        x = self.l1(x).relu().max_pool2d((2,2))\n",
    "        x = self.l2(x).relu().max_pool2d((2,2))\n",
    "        return self.l3(x.flatten(1).dropout(0.5))\n",
    "\n",
    "model = Model()\n",
    "optim = nn.optim.Adam(nn.state.get_parameters(model))\n",
    "\n",
    "batch_size = 128\n",
    "def step():\n",
    "    Tensor.training = True  # makes dropout work\n",
    "    samples = Tensor.randint(batch_size, high=X_train.shape[0])\n",
    "    X, Y = X_train[samples], Y_train[samples]\n",
    "    optim.zero_grad()\n",
    "    loss = model(X).sparse_categorical_crossentropy(Y).backward()\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "# JIT compile the training step\n",
    "jit_step = TinyJit(step)\n",
    "\n",
    "# Train model\n",
    "for step_num in range(7000):\n",
    "    loss = jit_step()\n",
    "    if step_num%100 == 0:\n",
    "        Tensor.training = False\n",
    "        acc = (model(X_test).argmax(axis=1) == Y_test).mean().item()\n",
    "        print(f\"step {step_num:4d}, loss {loss.item():.2f}, acc {acc*100.:.2f}%\")\n",
    "\n",
    "import timeit \n",
    "\n",
    "timeit.timeit(step, repeat=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
