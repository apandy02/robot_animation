{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinygrad.nn\n",
    "import numpy as np\n",
    "from tinygrad import nn , Tensor\n",
    "\n",
    "\n",
    "\n",
    "def layer_init(layer: nn.Linear, std=np.sqrt(2), bias_const=0.0):\n",
    "    \"\"\"CleanRL's default layer initialization\"\"\"\n",
    "    layer.weight = tiny_orthogonal_(layer.weight, std)\n",
    "    layer.bias = tiny_constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "from tinygrad import nn \n",
    "def tiny_orthogonal_(tensor: Tensor, gain=1, generator=None):\n",
    "    \"\"\"\n",
    "    NOTE: Since initialization occurs only once, we are being lazy and using numpy linear algebra to perform certain operations.\n",
    "    \"\"\"\n",
    "    if tensor.ndim < 2:\n",
    "        raise ValueError(\"Only tensors with 2 or more dimensions are supported\")\n",
    "\n",
    "    if tensor.numel() == 0:\n",
    "        return tensor # no-op for empty tensors\n",
    "\n",
    "    rows, cols = tensor.shape[0], tensor.numel() // tensor.shape[0]\n",
    "    flattened = Tensor.randn(rows, cols) # figure out if it has the same device configs as the input tensor\n",
    "\n",
    "    if rows < cols:\n",
    "        flattened = flattened.transpose()\n",
    "\n",
    "    # for now, we use numpy to compute the qr factorization\n",
    "    q, r = np.linalg.qr(flattened.numpy())\n",
    "\n",
    "    d = np.diag(r, 0)\n",
    "    ph = np.sign(d)\n",
    "    q *= ph\n",
    "\n",
    "    if rows < cols:\n",
    "        q.transpose()\n",
    "\n",
    "    return Tensor(q).mul(gain)\n",
    "\n",
    "def tiny_constant_(tensor: Tensor, val: float):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return Tensor.ones(tensor.shape) * val\n",
    "    \n",
    "\n",
    "from tinygrad import nn \n",
    "\n",
    "\n",
    "class TinyPolicy:\n",
    "    def __init__(self, policy):\n",
    "        self.policy = policy\n",
    "        self.is_continuous = hasattr(policy, 'is_continuous') and policy.is_continuous\n",
    "    \n",
    "    def __call__(self, x, action=None):\n",
    "        return self.get_action_and_value(x, action)\n",
    "\n",
    "    def get_value(self, x, state=None):\n",
    "        _, value = self.policy(x)\n",
    "        return value\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits, value = self.policy(x)\n",
    "        action, logprob, entropy = sample_logits(logits, action, self.is_continuous)\n",
    "        return action, logprob, entropy, value\n",
    "    \n",
    "class Critic:\n",
    "    def __init__(self, obs_size, hidden_size):\n",
    "        self.l1 = layer_init(tinygrad.nn.Linear(obs_size, hidden_size))\n",
    "        self.l2 = layer_init(tinygrad.nn.Linear(hidden_size, hidden_size))\n",
    "        self.l3 = layer_init(tinygrad.nn.Linear(hidden_size, 1))\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        x = self.l1(x).tanh()\n",
    "        x = self.l2(x).tanh()\n",
    "        return self.l3(x)\n",
    "\n",
    "class ActorEncoder:\n",
    "    def __init__(self, obs_size, hidden_size):\n",
    "        self.l1 = layer_init(tinygrad.nn.Linear(obs_size, hidden_size))\n",
    "        self.l2 = layer_init(tinygrad.nn.Linear(hidden_size, hidden_size))\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        x = self.l1(x).tanh()\n",
    "        return self.l2(x).tanh()\n",
    "\n",
    "class TinyCleanRLPolicy(TinyPolicy):\n",
    "    def __init__(self, envs, hidden_size=64):\n",
    "        super().__init__(policy=None)  # Just to get the right init\n",
    "        self.is_continuous = True\n",
    "\n",
    "        # self.obs_size = np.array(envs.single_observation_space.shape).prod()\n",
    "        # action_size = np.prod(envs.single_action_space.shape)\n",
    "\n",
    "        ## figuring out how to normalize observations will be an important step, but leaving it out for now\n",
    "        action_size = 1\n",
    "        self.obs_size = 1\n",
    "        self.critic = Critic(self.obs_size, hidden_size)\n",
    "        self.actor_encoder = ActorEncoder(self.obs_size, hidden_size)\n",
    "        self.actor_decoder_mean = layer_init(tinygrad.nn.Linear(hidden_size, action_size), std=0.01)\n",
    "        self.actor_decoder_logstd = Tensor.zeros(1, action_size)\n",
    "\n",
    "\n",
    "\n",
    "policy = TinyCleanRLPolicy(\"hypothetical env\", hidden_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "import torch\n",
    "a = Normal(torch.tensor([1.0, 2.0]), torch.tensor([1.0, 1.0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "a.log_prob(torch.tensor([1.0, 2.0])).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of c (10, 3)\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import TinyJit, Tensor\n",
    "weight = Tensor.randn(10, 3)\n",
    "@TinyJit\n",
    "def forward(x: Tensor, indices: list[int]):\n",
    "  c = (x[indices] * weight).contiguous()\n",
    "  print(f\"shape of c {c.shape}\")\n",
    "  c.sum(0).realize()\n",
    "\n",
    "x = Tensor.randn(10)\n",
    "forward(x, [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad impor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CPU time over 20 runs: 11.24s\n",
      "Average MPS time over 20 runs: 2.25s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Simple CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Linear(1600, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x).reshape(-1, 1600))\n",
    "\n",
    "# Data\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST('./', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "def train(device):\n",
    "    model = Net().to(device)\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            loss = nn.functional.cross_entropy(model(data), target)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "    return time.time() - start\n",
    "\n",
    "# Test CPU 20 times\n",
    "cpu_times = []\n",
    "for _ in range(20):\n",
    "    cpu_times.append(train('cpu'))\n",
    "avg_cpu_time = np.mean(cpu_times)\n",
    "print(f\"Average CPU time over 20 runs: {avg_cpu_time:.2f}s\")\n",
    "\n",
    "# Test MPS if available\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_times = []\n",
    "    for _ in range(20):\n",
    "        mps_times.append(train('mps'))\n",
    "    avg_mps_time = np.mean(mps_times)\n",
    "    print(f\"Average MPS time over 20 runs: {avg_mps_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m num_runs = \u001b[32m1\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_runs):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     tiny_cpu_times.append(\u001b[43mtrain_tiny\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     48\u001b[39m avg_tiny_cpu_time = np.mean(tiny_cpu_times)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAverage TinyGrad CPU time over 20 runs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_tiny_cpu_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtrain_tiny\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m     36\u001b[39m         loss = out.sparse_categorical_crossentropy(Y)\n\u001b[32m     37\u001b[39m         loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m time.time() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/nn/optim.py:33\u001b[39m, in \u001b[36mOptimizer.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     30\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m  Performs a single optimization step.\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m   Tensor.realize(*\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/nn/optim.py:42\u001b[39m, in \u001b[36mOptimizer.schedule_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03mReturns the tensors that need to be realized to perform a single optimization step.\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Tensor.training: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     40\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mTensor.training=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTensor.training\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Tensor.training must be enabled to use the optimizer.\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[33m            - help: Consider setting Tensor.training=True before calling Optimizer.step().\u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_step_with_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m+\u001b[38;5;28mself\u001b[39m.params+\u001b[38;5;28mself\u001b[39m.buffers\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/nn/optim.py:136\u001b[39m, in \u001b[36mLAMB.schedule_step_with_grads\u001b[39m\u001b[34m(self, grads)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mself\u001b[39m.m[i].assign(\u001b[38;5;28mself\u001b[39m.b1 * \u001b[38;5;28mself\u001b[39m.m[i] + (\u001b[32m1.0\u001b[39m - \u001b[38;5;28mself\u001b[39m.b1) * g)\n\u001b[32m    135\u001b[39m \u001b[38;5;28mself\u001b[39m.v[i].assign(\u001b[38;5;28mself\u001b[39m.b2 * \u001b[38;5;28mself\u001b[39m.v[i] + (\u001b[32m1.0\u001b[39m - \u001b[38;5;28mself\u001b[39m.b2) * (g * g))\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m m_hat = \u001b[38;5;28mself\u001b[39m.m[i] / (\u001b[32;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mb1_t\u001b[49m)\n\u001b[32m    137\u001b[39m v_hat = \u001b[38;5;28mself\u001b[39m.v[i] / (\u001b[32m1.0\u001b[39m - \u001b[38;5;28mself\u001b[39m.b2_t)\n\u001b[32m    138\u001b[39m up = (m_hat / (v_hat.sqrt() + \u001b[38;5;28mself\u001b[39m.eps)) + \u001b[38;5;28mself\u001b[39m.wd * t.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/ops.py:54\u001b[39m, in \u001b[36mSimpleMathTrait.__rsub__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3207\u001b[39m, in \u001b[36mTensor.sub\u001b[39m\u001b[34m(self, x, reverse)\u001b[39m\n\u001b[32m   3189\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3190\u001b[39m \u001b[33;03mSubtracts `x` from `self`.\u001b[39;00m\n\u001b[32m   3191\u001b[39m \u001b[33;03mEquivalent to `self - x`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3204\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m   3205\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3206\u001b[39m a, b = \u001b[38;5;28mself\u001b[39m._broadcasted(x, reverse)\n\u001b[32m-> \u001b[39m\u001b[32m3207\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/ops.py:43\u001b[39m, in \u001b[36mSimpleMathTrait.__add__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3186\u001b[39m, in \u001b[36mTensor.add\u001b[39m\u001b[34m(self, x, reverse)\u001b[39m\n\u001b[32m   3168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:Union[Tensor, ConstType], reverse=\u001b[38;5;28;01mFalse\u001b[39;00m) -> Tensor:\n\u001b[32m   3169\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3170\u001b[39m \u001b[33;03m  Adds `self` and `x`.\u001b[39;00m\n\u001b[32m   3171\u001b[39m \u001b[33;03m  Equivalent to `self + x`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3184\u001b[39m \u001b[33;03m  ```\u001b[39;00m\n\u001b[32m   3185\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3186\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_broadcasted_uop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUOp\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:191\u001b[39m, in \u001b[36mTensor._apply_broadcasted_uop\u001b[39m\u001b[34m(self, fxn, x, reverse)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_apply_broadcasted_uop\u001b[39m(\u001b[38;5;28mself\u001b[39m, fxn:Callable, x:Union[Tensor, ConstType], reverse=\u001b[38;5;28;01mFalse\u001b[39;00m) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m   lhs,rhs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_broadcasted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m lhs._apply_uop(fxn, rhs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3981\u001b[39m, in \u001b[36m_metadata_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m3981\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA.get() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3983\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA >= \u001b[32m2\u001b[39m:\n\u001b[32m   3984\u001b[39m     caller_frame = sys._getframe(frame := \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:3166\u001b[39m, in \u001b[36mTensor._broadcasted\u001b[39m\u001b[34m(self, y, reverse, match_dtype)\u001b[39m\n\u001b[32m   3163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reverse: x, y = y, x\n\u001b[32m   3165\u001b[39m \u001b[38;5;66;03m# broadcast\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x._broadcast_to(out_shape:=_broadcast_shape(\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m, y.shape)), y._broadcast_to(out_shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/tensor.py:226\u001b[39m, in \u001b[36mTensor.shape\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[sint, ...]: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazydata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/weekend_experiments/robot_animation/.venv/lib/python3.11/site-packages/tinygrad/ops.py:316\u001b[39m, in \u001b[36mUOp.shape\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    312\u001b[39m   \u001b[38;5;66;03m# TODO: this should check if st is None, it cannot because local reduce has implicit movement ops\u001b[39;00m\n\u001b[32m    313\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(smax(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*[x.full_shape \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.src \u001b[38;5;28;01mif\u001b[39;00m x.op \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {Ops.DEFINE_GLOBAL,Ops.DEFINE_LOCAL} \\\n\u001b[32m    314\u001b[39m       \u001b[38;5;66;03m# TODO: this exists because wmma creates consts without ShapeTracker in the AST, there's probably a way to fix this\u001b[39;00m\n\u001b[32m    315\u001b[39m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (x.op \u001b[38;5;129;01mis\u001b[39;00m Ops.CONST \u001b[38;5;129;01mand\u001b[39;00m x.st \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)]))\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[sint, ...]: \u001b[38;5;28;01mreturn\u001b[39;00m unwrap(\u001b[38;5;28mself\u001b[39m.st).shape\n\u001b[32m    318\u001b[39m \u001b[38;5;129m@property\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# TinyGrad implementation\n",
    "from tinygrad import Tensor, nn, Device\n",
    "from tinygrad.nn.datasets import mnist\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting TinyGrad implementation...\")\n",
    "\n",
    "Device.DEFAULT = \"METAL\"\n",
    "print(f\"Using device: {Device.DEFAULT}\")\n",
    "\n",
    "class TinyNet:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing TinyNet model...\")\n",
    "        self.l1 = nn.Conv2d(1, 32, kernel_size=(3,3))\n",
    "        self.l2 = nn.Conv2d(32, 64, kernel_size=(3,3))\n",
    "        self.l3 = nn.Linear(1600, 10)\n",
    "\n",
    "    def __call__(self, x:Tensor) -> Tensor:\n",
    "        x = self.l1(x).relu().max_pool2d((2,2))\n",
    "        x = self.l2(x).relu().max_pool2d((2,2))\n",
    "        return self.l3(x.flatten(1))\n",
    "\n",
    "# Get MNIST data\n",
    "print(\"Loading MNIST dataset...\")\n",
    "X_train, Y_train, X_test, Y_test = mnist()\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "\n",
    "@Tensor.train()\n",
    "def train_tiny(device=None):  # device param kept for consistency but not used since tinygrad handles it\n",
    "    print(\"\\nStarting training...\")\n",
    "    model = TinyNet()\n",
    "    optim = nn.optim.Adam(nn.state.get_parameters(model))\n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(1):  # Match PyTorch's 1 epoch\n",
    "        print(f\"\\nEpoch {epoch+1}\")\n",
    "        for i in range(0, len(X_train), 128):  # Match PyTorch's batch size\n",
    "            samp = slice(i, i+128)\n",
    "            X, Y = X_train[samp], Y_train[samp]\n",
    "            optim.zero_grad()\n",
    "            out = model(X)\n",
    "            loss = out.sparse_categorical_crossentropy(Y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "\n",
    "    training_time = time.time() - start\n",
    "    print(f\"Training completed in {training_time:.2f}s\")\n",
    "    return training_time\n",
    "\n",
    "# Test CPU 20 times\n",
    "tiny_cpu_times = []\n",
    "\n",
    "print(\"\\nStarting timing runs...\")\n",
    "num_runs = 1\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\nRun {run+1}/{num_runs}\")\n",
    "    tiny_cpu_times.append(train_tiny())\n",
    "avg_tiny_cpu_time = np.mean(tiny_cpu_times)\n",
    "print(f\"\\nAverage TinyGrad CPU time over {num_runs} runs: {avg_tiny_cpu_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
